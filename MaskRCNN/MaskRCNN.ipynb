{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeeDKJdvq17L"
   },
   "source": [
    "# Training and evaluating custom data using Mask R-CNN\n",
    "\n",
    "This notebook shows a step-by-step guide to training and evaluating the custom image data using our modified Mask R-CNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zu4De1wrc2p"
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsYxv75lq17S"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline # display matplotlib-generated plots directly within the notebook\n",
    "import yaml\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the root directory, e.g., ShinyAnimalCV/ShinyAnimalCV_SourceCode/\n",
    "ROOT_DIR = os.path.abspath(\"/Users/xiaolanbao/Dropbox (Personal)/ShinyAnimalCV/ShinyAnimalCV_SourceCode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modified Mask R-CNN from `mrcnn`\n",
    "\n",
    "The `mrcnn/` can be downloaded from https://github.com/uf-aiaos/ShinyAnimalCV/tree/main/ShinyAnimalCV_SourceCode/mrcnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(ROOT_DIR)\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEHVxGoLq17V"
   },
   "source": [
    "## Set up the hyperparameters for Mask R-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fW7B4PKFq17W",
    "outputId": "ee89171b-d18e-458d-99de-e6cd515c30e4"
   },
   "outputs": [],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training custom data.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name, such as pig when training pig image data\n",
    "    NAME = \"pig\"\n",
    "    # Train on 1 GPU and 1 images per GPU. Batch size is equal to 1 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    BACKBONE = \"resnet50\" # here we use resnet50 for training small dataset \n",
    "    # Number of classes \n",
    "    NUM_CLASSES = 1 + 1 # background + stem \n",
    "    # set up steps per epoch\n",
    "    STEPS_PER_EPOCH = 30\n",
    "    # confidence score\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    # set up image dim\n",
    "    IMAGE_MIN_DIM = 400\n",
    "    # Set mini mask to false; It is TRUE in default config\n",
    "    USE_MINI_MASK = False\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBu_QZ7Uq17b"
   },
   "source": [
    "## Define a class of `Dataset` to import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Oa8zGnvq17c"
   },
   "outputs": [],
   "source": [
    "class Dataset(utils.Dataset):\n",
    "    # get the number of objects\n",
    "    def get_obj_index(self, image):\n",
    "        n = np.max(image)\n",
    "        return n\n",
    "    \n",
    "    # interpret the yaml file \n",
    "    def from_yaml_get_class(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        with open(info['yaml_path']) as f:\n",
    "            temp = yaml.full_load(f.read())\n",
    "            labels = temp['label_name']\n",
    "            del labels[0]\n",
    "        return labels\n",
    "    \n",
    "    def draw_mask(self, num_obj, mask, image,image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        for index in range(num_obj):\n",
    "            for i in range(info['width']):\n",
    "                for j in range(info['height']):\n",
    "                    at_pixel = image.getpixel((i, j))\n",
    "                    if at_pixel == index + 1:\n",
    "                        mask[j, i, index] = 1\n",
    "        return mask\n",
    "\n",
    "    def load_shapes(self, img_floder, mask_floder, dataset_root_path):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"pig\") # replace pig with the label name that you created when labeling the data \n",
    "        imglist = os.listdir(img_floder)\n",
    "        for i in range(0, len(imglist)):\n",
    "            filestr   = imglist[i].split(\".\")[0]\n",
    "            mask_path = mask_floder + \"/\" + filestr + \".png\"\n",
    "            yaml_path = dataset_root_path + \"labelme_json/\" + filestr + \"_json/info.yaml\"\n",
    "            cv_img    = cv2.imread(img_floder + \"/\" + filestr + \".png\")\n",
    "            print('cv_img: ', i, img_floder + \"/\" + filestr + \".png\")\n",
    "            self.add_image(\"shapes\", image_id=i, path=img_floder + \"/\" + imglist[i],\n",
    "                               width=cv_img.shape[1], height=cv_img.shape[0], mask_path=mask_path, yaml_path=yaml_path)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info  = self.image_info[image_id]\n",
    "        count = 1  # number of object\n",
    "        img   = Image.open(info['mask_path'])\n",
    "        num_obj   = self.get_obj_index(img)\n",
    "        mask  = np.zeros([info['height'], info['width'], num_obj], dtype=np.uint8)\n",
    "        mask  = self.draw_mask(num_obj, mask, img,image_id)\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        labels = []\n",
    "        labels = self.from_yaml_get_class(image_id)\n",
    "        labels_form = []\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i].find(\"pig\") != -1:\n",
    "                labels_form.append(\"pig\")\n",
    "        class_ids = np.array([self.class_names.index(s) for s in labels_form])\n",
    "        return mask, class_ids.astype(np.int32)\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size * cols, size * rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the path to the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVfXuY61r7SP",
    "outputId": "171ba718-f687-44c3-dbb8-58a3a0fe934e"
   },
   "outputs": [],
   "source": [
    "# Fill the actual folder path which contains your training dataset, validation dataset, testing dataset, and cv2_mask.\n",
    "dataset_root_path=\"/Users/xiaolanbao/Dropbox (Personal)/ShinyAnimalCV/ExampleData/Example_images_for_training_and_evaluating_model/\"\n",
    "\n",
    "# set the path to train, validationl, and test images\n",
    "img_train_floder = dataset_root_path + \"pic_train\"\n",
    "img_val_floder = dataset_root_path + \"pic_val\"\n",
    "img_test_floder = dataset_root_path + \"pic_test\"\n",
    "\n",
    "# set the path to mask images\n",
    "mask_floder = dataset_root_path + \"cv2_mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oYg2lMJq17f",
    "outputId": "072777e9-7f91-4b56-aa6b-d41102ffe4df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "print(\"train dataset\")\n",
    "dataset_train = Dataset()\n",
    "dataset_train.load_shapes(img_train_floder, mask_floder, dataset_root_path)\n",
    "dataset_train.prepare()\n",
    "\n",
    "#load validation dataset\n",
    "print(\"validation dataset\")\n",
    "dataset_val = Dataset()\n",
    "dataset_val.load_shapes(img_val_floder, mask_floder, dataset_root_path)\n",
    "dataset_val.prepare()\n",
    "\n",
    "#load test dataset\n",
    "print(\"test dataset\")\n",
    "dataset_test = Dataset()\n",
    "dataset_test.load_shapes(img_test_floder, mask_floder, dataset_root_path)\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and display a random image to check if data is loaded successfully (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "Fjybb7f1q17g",
    "outputId": "e2aba0fb-1b9d-4c9b-b3b3-d329e995895c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(dataset_train.image_ids, 1)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)\n",
    "    print(dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ii_m4nRq17h"
   },
   "source": [
    "## Build Mask R-CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training model \n",
    "\n",
    "This section shows how to create a Mask R-CNN model and specify the initial weights for training. Below are two ways to set up the initial weights: \n",
    "\n",
    "- COCO Pretrained Weights: If you are training your model on a new dataset for the first time, it is generally recommended to initialize your model with pretrained weights from a large public dataset, such as COCO.\n",
    "\n",
    "- Last Training Weights: If you want to continue training the model based on previous results or your training was interrupted for some reason and you want to resume your training from where you left off rather than starting over. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EdVothj5hPx"
   },
   "outputs": [],
   "source": [
    "# directory to save logs and trained models\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# create model in training mode\n",
    "model = modellib.MaskRCNN(mode =\"training\", config= config, model_dir = MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbt4hynlq17i",
    "outputId": "1a9a6274-c39c-4680-9cb5-519d54c17a7a"
   },
   "outputs": [],
   "source": [
    "# specify which initial weight to start with: \"coco\" or \"last\"\n",
    "init_with = \"coco\" # here we use \"coco\" as an exmaple \n",
    "\n",
    "# local path to coco weights \n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# download coco weights if it is not available in local\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    \n",
    "if init_with == \"coco\":\n",
    "    # load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_a9aXxsq17p"
   },
   "source": [
    "#### Start model training\n",
    "\n",
    "Here we trained the model following three stages:\n",
    "1. Only train the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine tune `4+` layers. Pass `layers='4+'` to the `train()` function.\n",
    "\n",
    "3. Fine tune all layers. Pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51fdLLU0q17r",
    "outputId": "411710c0-6e58-4001-ad8f-a9d77835dc0f"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard # this will print out the log of model training \n",
    "\n",
    "# Stage 1 \n",
    "print(\"Training network heads\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=10,\n",
    "            layers='heads'\n",
    "            )\n",
    "\n",
    "# Stage 2\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=15,\n",
    "            layers='4+'\n",
    "            )\n",
    "\n",
    "# Stage 3\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=20,\n",
    "            layers='all'\n",
    "            )\n",
    "\n",
    "print(\"finished training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an inference model and load trained weights obtained from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configurations for the inference model \n",
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8\n",
    "    USE_MINI_MASK = False\n",
    "    \n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Create a model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Here you need to provide your actual path for your trained weights\n",
    "model_path = \"/Users/xiaolanbao/Dropbox (Personal)/UF/Projects/ShinyAnimalCV/Mask_RCNN/MaskRCNN_OnePig_RGB/logs/pig_heatmap/mask_rcnn_pig_heatmap_0060.h5\"\n",
    "\n",
    "# Load trained weights to the inference model \n",
    "print(\"Loading weights from \", model_path)\n",
    "tf.keras.Model.load_weights(model.keras_model, model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model using a random image\n",
    "image_id = 3\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_test, inference_config, \n",
    "                           image_id)\n",
    "\n",
    "# apply the trained model to the image \n",
    "results = model.detect([original_image], verbose=1)\n",
    "r       = results[0]\n",
    "\n",
    "# visualize the results \n",
    "## get the information of minimum rotated bounding box using `morphologicalfeatures` function\n",
    "outputs = visualize.morphologicalfeatures(r['masks'], r['class_ids'], dataset_test.class_names)\n",
    "mf = outputs['morpholdf']\n",
    "minbox  = outputs['minbox'] # coordinate of minbox\n",
    "rangle  = outputs['rangle'] # angle of minbox \n",
    "\n",
    "## display the detected and segmented results \n",
    "visualize.display_instances_md(original_image, minbox, rangle, r['masks'], r['class_ids'], \n",
    "                            dataset_test.class_names, r['scores'], ax=get_ax())\n",
    "\n",
    "mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model performance using average precision\n",
    "The average precision (AP) is calculated by averaging the precision over all recall values from 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mAP for all testing images' AP\n",
    "def evaluate_model(dataset, model, cfg, iou_threshold = 0.5):\n",
    "    APs = list()\n",
    "    for image_id in dataset.image_ids:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset, cfg, image_id)\n",
    "        results = model.detect([image], verbose = 1)\n",
    "        r = results[0]\n",
    "        AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'], \n",
    "                                                             iou_threshold = iou_threshold)\n",
    "        APs.append(AP)\n",
    "    mAP = np.mean(APs)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mAP for dataset_test by using trained model and inference configuration.\n",
    "mAP = evaluate_model(dataset_test, model, inference_config)\n",
    "print(f\"mAP: {mAP}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
